{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051672f-e87e-424a-8899-47d64d8f604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26836826-9593-4d7c-8c18-9a993bd8248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkg_dir = \"/kaggle/input/sumo-sennet-2024-02-10-19-53-46\"\n",
    "pkg_dir = \"/home/clay/research/kaggle/sennet\"\n",
    "\n",
    "\n",
    "# DATASET_FOLDER = \"/kaggle/input/blood-vessel-segmentation\"\n",
    "DATASET_FOLDER = \"/home/clay/research/kaggle/sennet/data/blood-vessel-segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde39c5a-8f18-4142-8ccc-2bcb585db06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(f\"{pkg_dir}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cb1ce-54cb-4f19-b83a-b03afefc8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c482ee1-89c9-4239-b9a1-9fe3f81c0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sennet.core.submission_utils import load_model_from_dir\n",
    "from sennet.environments.constants import MODEL_OUT_DIR\n",
    "\n",
    "\n",
    "print(f\"{MODEL_OUT_DIR=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef2a55-4402-4e2a-96bf-6c629407eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "import gc\n",
    "import monai\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b875ff9-2a1c-4df5-9ff4-d0bf4c209161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "\n",
    "submission_path = f\"{pkg_dir}/configs/submission.yaml\"\n",
    "with open(submission_path, \"rb\") as f:\n",
    "    submission_cfg = yaml.load(f, yaml.FullLoader)\n",
    "print(json.dumps(submission_cfg, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7343fa-0635-4d93-817b-0a834747180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_models = []\n",
    "weights = []\n",
    "\n",
    "use_top_only = True #True\n",
    "use_best = False # False\n",
    "folds2predict = [0]\n",
    "# folds2predict = [1]\n",
    "\n",
    "use_tta = True\n",
    "\n",
    "TH = 0.01\n",
    "\n",
    "is_test = True\n",
    "# is_test = not len(glob(os.path.join(DATASET_FOLDER, \"test\", \"*\", \"*\", \"*.tif\"))) == 6\n",
    "# is_test = not len(glob(os.path.join(DATASET_FOLDER, \"train\", \"*\", \"*\", \"*.tif\"))) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ca89e-521b-4dcc-8b11-414240a3dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_keys(original_dict, pattern):\n",
    "#     new_dict = {}\n",
    "    \n",
    "#     for old_key, value in original_dict.items():\n",
    "#         new_key = re.sub(pattern, '', old_key)\n",
    "        \n",
    "#         new_dict[new_key] = value\n",
    "    \n",
    "#     return new_dict\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    if rle=='':\n",
    "        rle = '1 0'\n",
    "    return rle\n",
    "\n",
    "\n",
    "def to_device(x: torch.Tensor, cuda_id: int = 0) -> torch.Tensor:\n",
    "    return x.cuda(cuda_id) if torch.cuda.is_available() else x\n",
    "\n",
    "\n",
    "# def load_jit_model(model_path: str, cuda_id: int = 0) -> torch.nn.Module:\n",
    "#     model = torch.jit.load(\n",
    "#         model_path,\n",
    "#         map_location=f\"cuda:{cuda_id}\" if torch.cuda.is_available() else \"cpu\",\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd931087-270c-4d2d-b2c1-3f78ced785ce",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28a9e3-8877-4e31-a598-faf65e57ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, in_channels=3, is_test=False):\n",
    "        self.window = in_channels // 2\n",
    "        self.is_test = is_test\n",
    "        self.ids = []\n",
    "\n",
    "        self.data_tensor = self.load_volume(dataset)\n",
    "        self.shape_orig = self.data_tensor.shape\n",
    "\n",
    "        padding = (\n",
    "            (self.window, self.window),\n",
    "        ) * self.data_tensor.ndim\n",
    "\n",
    "        self.padding = tuple(\n",
    "            (max(0, before), max(0, after)) for (before, after) in padding\n",
    "        )\n",
    "        self.data_tensor = np.pad(\n",
    "            self.data_tensor, padding, mode=\"constant\", constant_values=0\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.shape_orig) if self.is_test else self.shape_orig[0]\n",
    "\n",
    "    def normilize(self, image):\n",
    "        image = (image - self.xmin) / (self.xmax - self.xmin)\n",
    "        # image = np.clip(image, 0, 1)\n",
    "        image = (image - 0.5) / 0.235\n",
    "        \n",
    "        return image.astype(np.float32)\n",
    "    \n",
    "    @staticmethod\n",
    "    # def norm_by_percentile(volume, low=10, high=99.8):\n",
    "    def norm_by_percentile(volume, low=1, high=99):\n",
    "        # assert False, f\"{volume.shape=}\"\n",
    "        channel_margin = 0.2\n",
    "        channel_lb = int(channel_margin * volume.shape[0])\n",
    "        channel_ub = int((1 - channel_margin) * volume.shape[0])\n",
    "        \n",
    "        xmin = np.percentile(volume[channel_lb: channel_ub], low)\n",
    "        xmax = np.max([np.percentile(volume[channel_lb: channel_ub], high), 1])\n",
    "        print(f\"{xmin=}, {xmax=}\")\n",
    "        return xmin, xmax\n",
    "\n",
    "    def load_volume(self, dataset):\n",
    "        path = os.path.join(dataset, \"images\", \"*.tif\")\n",
    "        dataset = sorted(glob(path))\n",
    "        for p_img in tqdm(dataset):\n",
    "            path_ = p_img.split(os.path.sep)\n",
    "            slice_id, _ = os.path.splitext(path_[-1])\n",
    "            self.ids.append(f\"{path_[-3]}_{slice_id}\")\n",
    "            \n",
    "        volume = None\n",
    "\n",
    "        for z, path in enumerate(tqdm(dataset)):\n",
    "            image = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "            image = np.array(image, dtype=np.uint16)\n",
    "            if volume is None:\n",
    "                volume = np.zeros((len(dataset), *image.shape[-2:]), dtype=np.uint16)\n",
    "            volume[z] = image\n",
    "        self.xmin, self.xmax = self.norm_by_percentile(volume)\n",
    "        return volume\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine which axis to sample from based on the index\n",
    "        if idx < self.shape_orig[0]:\n",
    "            idx = idx + self.window\n",
    "            slice_data = self.normilize(\n",
    "                self.data_tensor[\n",
    "                    idx - self.window : 1 + idx + self.window, :, :\n",
    "                ].transpose(1, 2, 0)[self.window:-self.window, self.window:-self.window, :]\n",
    "            )\n",
    "            axis = \"X\"\n",
    "            idx -= 1\n",
    "\n",
    "        elif idx < self.shape_orig[0] + self.shape_orig[1]:\n",
    "            idx -= (self.shape_orig[0] - self.window)\n",
    "            slice_data = self.normilize(\n",
    "                self.data_tensor[\n",
    "                    :, idx - self.window : 1 + idx + self.window, :\n",
    "                ].transpose(0, 2, 1)[self.window:-self.window, self.window:-self.window, :]\n",
    "            )\n",
    "            axis = \"Y\"\n",
    "            idx -= 1\n",
    "\n",
    "            \n",
    "        else:\n",
    "            idx -= (\n",
    "                self.shape_orig[0]\n",
    "                + self.shape_orig[1]\n",
    "                - self.window\n",
    "            ) \n",
    "            \n",
    "            slice_data = self.normilize(\n",
    "                self.data_tensor[\n",
    "                    :, :, idx - self.window : 1 + idx + self.window\n",
    "                ][self.window:-self.window, self.window:-self.window, :]\n",
    "            )\n",
    "            axis = \"Z\"\n",
    "            idx -= 1\n",
    "\n",
    "        slice_data = torch.tensor(slice_data.transpose(2, 0, 1))\n",
    "\n",
    "        return {\n",
    "            \"slice\": slice_data,\n",
    "            \"slice_index\": idx,\n",
    "            \"axis\": axis\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89f5c0-11c8-4f77-837a-909a93f0f720",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbb6ff-04ea-4c44-bd2a-374113ab719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_highest_score_filename(file_list):\n",
    "#     highest_score = float('-inf')\n",
    "#     highest_score_filename = None\n",
    "\n",
    "#     for filename in file_list:\n",
    "#         # Extract the score from the filename using regular expression\n",
    "#         match = re.search(r'dice_(\\d+\\.\\d+)', filename)\n",
    "#         if match:\n",
    "#             current_score = float(match.group(1))\n",
    "#             if current_score > highest_score:\n",
    "#                 highest_score = current_score\n",
    "#                 highest_score_filename = filename\n",
    "\n",
    "#     return highest_score_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35371966-aed9-4b40-9078-eb5f981a3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, our_model):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.model = our_model\n",
    "\n",
    "    def forward(self, img):\n",
    "        # print(f\"{img.shape=}\")\n",
    "        # print(f\"{img}\")\n",
    "        res = self.model.predict(img.unsqueeze(1))\n",
    "        return res.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daaa044-fb06-4335-85f8-e721b79be658",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = []\n",
    "\n",
    "for model_config in tqdm(submission_cfg[\"predictors\"][\"models\"]):\n",
    "    for fold in folds2predict:\n",
    "        if use_top_only:\n",
    "            # model_path = sorted(glob(f\"/kaggle/input/senet-hoa/{model_config[3]}/{fold}/checkpoints/epoch*.ckpt\"))[-1]\n",
    "            # print(f\"use_top_only, loading: {model_path}\")\n",
    "            # state_dict = rename_keys(torch.load(model_path, map_location=\"cpu\")[\"state_dict\"], \"net.\")\n",
    "            # model = to_device(smp.create_model(arch=model_config[0], encoder_name=model_config[1], in_channels=model_config[2], encoder_weights=None, decoder_attention_type=model_config[5]))\n",
    "            # model.load_state_dict(state_dict)\n",
    "            # model.eval()\n",
    "            cfg, raw_model = load_model_from_dir(MODEL_OUT_DIR / model_config)\n",
    "            raw_model = raw_model.cuda().eval()\n",
    "            model_in_chans = raw_model.kw[\"in_channels\"]\n",
    "            model = ModelWrapper(raw_model)\n",
    "            \n",
    "            if use_tta:\n",
    "                tta_models.append(tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')) #flip_transform d4_transform\n",
    "            else:\n",
    "                tta_models.append(model)\n",
    "            \n",
    "            weights.append(1.0)\n",
    "            in_chans.append(model_in_chans)\n",
    "            \n",
    "        elif use_best:\n",
    "            raise NotImplementedError(\"don't use this\")\n",
    "        else:\n",
    "            raise NotImplementedError(\"don't use this\")\n",
    "\n",
    "\n",
    "print(f\"{in_chans=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338e1a3-12f5-47d9-ad81-b89212e1ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81320e-f6e4-4449-8b3e-6de128ab845a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9c029-9c67-4d06-80cc-2c4cdf27b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"/home/clay/research/kaggle/sennet/data/blood-vessel-segmentation/train/kidney_3_dense/\"]\n",
    "# datasets = sorted(glob(f\"{DATASET_FOLDER}/test/*\"))[::-1]\n",
    "print(f\"{datasets=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ebc59-efe4-4e81-9037-80b334421dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rles, ids = [], []\n",
    "with torch.no_grad():\n",
    "    for dataset in datasets:\n",
    "#         test_dataset[2][\"slice\"][1,...].unsqueeze(0).shape\n",
    "        test_dataset = BuildDataset(dataset, is_test=is_test, in_channels=3) # TODO: refactor this\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, num_workers=4, shuffle=False, pin_memory=False)\n",
    "\n",
    "        y_preds = np.zeros(test_dataset.shape_orig, dtype=np.half)\n",
    "        ids += test_dataset.ids\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc=f'Inference {dataset}')\n",
    "        for step, batch in pbar:\n",
    "            images = to_device(batch[\"slice\"])\n",
    "            \n",
    "            # print(images.shape)\n",
    "            axis = batch[\"axis\"][0]\n",
    "            idx = batch[\"slice_index\"].numpy()[0]\n",
    "\n",
    "            preds = 0\n",
    "            for tta_model, weight, in_chan in zip(tta_models, weights, in_chans):\n",
    "                preds += weight * monai.inferers.sliding_window_inference(\n",
    "                    inputs=images if in_chan != 1 else images[:, 1,...].unsqueeze(0),\n",
    "                    predictor=tta_model,\n",
    "                    sw_batch_size=8,\n",
    "                    roi_size=(800, 800),\n",
    "                    # overlap=0.25,\n",
    "                    overlap=0.5,\n",
    "                    # overlap=0.9,\n",
    "                    padding_mode=\"reflect\",\n",
    "                    mode=\"gaussian\",\n",
    "                    # mode=\"constant\",\n",
    "                    sw_device=\"cuda\",\n",
    "                    device=\"cuda\",\n",
    "                    progress=False,\n",
    "                )\n",
    "            if axis == \"X\":\n",
    "                y_preds[idx, :, :] += ((preds / sum(weights)).squeeze().sigmoid().cpu().numpy() / 3.).astype(np.half)\n",
    "            elif axis == \"Y\":\n",
    "                y_preds[:, idx, :] += ((preds / sum(weights)).squeeze().sigmoid().cpu().numpy() / 3.).astype(np.half)\n",
    "            elif axis == \"Z\":\n",
    "                y_preds[:, :, idx] += ((preds / sum(weights)).squeeze().sigmoid().cpu().numpy() / 3.).astype(np.half)\n",
    "        \n",
    "       # y_preds = cc3d.dust(\n",
    "         #       (y_preds > TH).astype(np.uint8),\n",
    "             #   connectivity=18,\n",
    "            #    threshold=-1,\n",
    "           #     in_place=False\n",
    "         #   )\n",
    "        \n",
    "        for pred in y_preds:\n",
    "            rles.append(rle_encode((pred > TH).astype(np.uint8)))\n",
    "            # rles.append(rle_encode((pred)))\n",
    "\n",
    "        del test_dataset, test_loader, y_preds\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a083ca-f913-4c26-8386-24977f33f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = BuildDataset(datasets[0], is_test=is_test, in_channels=3)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a5136-1451-43d7-9368-20bd3fb6371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0][\"slice\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd09eec-6bb8-4020-9381-d2a3fe9f643b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0123a-086a-4e5c-b31a-c3d67e0009b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    \"id\": ids,\n",
    "    \"rle\": rles\n",
    "})\n",
    "\n",
    "submission[\"height\"] = 1706\n",
    "submission[\"width\"] = 1510\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.to_csv(\"/opt/kaggle/sennet/data_dumps/predicted/igor/kidney_3_dense/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2904e-3c34-496f-8443-74fb0ad74f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b690b-b6ac-43ca-a897-ffa29d692937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
