{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf30fac",
   "metadata": {
    "papermill": {
     "duration": 0.005789,
     "end_time": "2024-01-05T10:47:15.333431",
     "exception": false,
     "start_time": "2024-01-05T10:47:15.327642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Inference: \n",
    "This notebook 0.859  \n",
    "\n",
    "Version 9\n",
    "\n",
    "model:\n",
    "/kaggle/input/sn-hoa-8e-5-27-rot0-5/se_resnext50_32x4d_26_loss0.10_score0.90_val_loss0.12_val_score0.88_midd_1024.pt.  From dataset «sn-hoa-8e-5-27-rot0-5» Version 1 name of version \"Version 1 - Initial release\"\n",
    "\n",
    "idia 0:        \n",
    "         th_percentile = 0.00143                            (-> 0.859)\n",
    "         model_path_i = 9\n",
    "\n",
    "# Train: \n",
    "https://www.kaggle.com/nguynvnthtr/the-training-image-is-1024-x-1024  \n",
    "\n",
    "version 1\n",
    "\n",
    "idia  : image_size = 1024\n",
    "\n",
    "idia 1:\n",
    "\n",
    "        x_index= (x.shape[1]-self.image_size)//2 \n",
    "        \n",
    "        y_index= (x.shape[2]-self.image_size)//2   (-> 0.628)\n",
    "        \n",
    "idia 2:\n",
    "     \n",
    "        p_augm = 0.05  #probability of augmentaton changed to 0.05    (-> 0.686)\n",
    "        \n",
    "\n",
    "    \n",
    "idia 3:\n",
    "\n",
    "        in_chans = 1  #window for moov label changed to 1    (-> 0.800)\n",
    "        \n",
    "idia 4:\n",
    " \n",
    "        Epoch = 27                                           (-> 0.856)\n",
    "\n",
    "\n",
    "idia 5:\n",
    "\n",
    "        lr = 8e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cd26e",
   "metadata": {
    "papermill": {
     "duration": 0.004793,
     "end_time": "2024-01-05T10:47:15.343677",
     "exception": false,
     "start_time": "2024-01-05T10:47:15.338884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# All get from:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3c48c",
   "metadata": {
    "papermill": {
     "duration": 0.005035,
     "end_time": "2024-01-05T10:47:15.353810",
     "exception": false,
     "start_time": "2024-01-05T10:47:15.348775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This code is base on [2.5d segmentaion baseline [inference]](https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-inference)**\n",
    "If you think my code is useful,please upvote it ^w^.\n",
    "* Version2:\n",
    "1. *     updata normalization method\n",
    "2. *     image_size = 512\n",
    "3. *     useing 3d TTA\n",
    "4. *     se_resnext50_32x4d\n",
    "\n",
    "* Version3:\n",
    "1. *     updata normalization method\n",
    "\n",
    "* This version is correspond with [2.5d segmentaion baseline [training]](https://www.kaggle.com/code/yoyobar/2-5d-cutting-model-baseline-training) version6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebb2fe",
   "metadata": {
    "papermill": {
     "duration": 0.00482,
     "end_time": "2024-01-05T10:47:15.363758",
     "exception": false,
     "start_time": "2024-01-05T10:47:15.358938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68907d07",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 26.136907,
     "end_time": "2024-01-05T10:47:41.505890",
     "exception": false,
     "start_time": "2024-01-05T10:47:15.368983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch as tc \n",
    "import torch.nn as nn  \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "import cv2\n",
    "import os,sys\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# !python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37218a1b",
   "metadata": {
    "papermill": {
     "duration": 0.007314,
     "end_time": "2024-01-05T10:47:41.520908",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.513594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d23b6f",
   "metadata": {
    "papermill": {
     "duration": 0.018028,
     "end_time": "2024-01-05T10:47:41.546797",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.528769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path_i = 11 # 9 # 7 #5 #in_chans_1__25     3 in_chans_1__20 2 \n",
    "class CFG:\n",
    "# ============== model CFG =============\n",
    "    model_name = 'Unet'\n",
    "    backbone = 'se_resnext50_32x4d'\n",
    "\n",
    "    in_chans = 1 #5 # 65\n",
    "    #============== _ CFG =============\n",
    "    image_size = 1024 #512\n",
    "    input_size= 1024 #512\n",
    "    # image_size = 512\n",
    "    # input_size= 512\n",
    "    tile_size = image_size\n",
    "    # stride = tile_size // 4  # TODO(Sumo): substride is here\n",
    "    stride = tile_size\n",
    "    drop_egde_pixel= 0 # 16 #32\n",
    "    \n",
    "    target_size = 1\n",
    "    chopping_percentile=1e-3\n",
    "    # ============== fold =============\n",
    "    valid_id = 1\n",
    "    batch=16 #128\n",
    "    th_percentile = 0.0014900 #0.00143 #0.00145 #0.00146 #0.00149 #0.00145 # 0.0014 #0.00175 #0.0021\n",
    "    \n",
    "    #axis_w = [0.3353333 ,0.3323333,0.3323333 ]\n",
    "    model_path=[\"/kaggle/input/2-5d-cutting-model-baseline-training/se_resnext50_32x4d_19_loss0.12_score0.79_val_loss0.25_val_score0.79.pt\",\n",
    "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.09_score0.83_val_loss0.28_val_score0.83.pt\",\n",
    "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.05_score0.90_val_loss0.25_val_score0.86.pt\",\n",
    "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.05_score0.89_val_loss0.24_val_score0.86_midd.pt\",\n",
    "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_24_loss0.05_score0.90_val_loss0.23_val_score0.88_midd.pt\",\n",
    "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_24_loss0.04_score0.91_val_loss0.23_val_score0.88_midd.pt\", # 25 025 rot 512 center\n",
    "               \"/kaggle/input/blood-vessel-model-1024/se_resnext50_32x4d_24_loss0.10_score0.90_val_loss0.16_val_score0.85_midd_1024.pt\",\n",
    "               \"/kaggle/input/blood-vessel-model-1024/se_resnext50_32x4d_24_loss0.10_score0.90_val_loss0.12_val_score0.88_midd_1024.pt\",# lr = 8e-5\n",
    "               \"/kaggle/input/blood-vessel-model-1024/se_resnext50_32x4d_24_loss0.91_score0.09_val_loss0.91_val_score0.09_midd_1024.pt\", #  60e-5 \n",
    "               \"/kaggle/input/sn-hoa-8e-5-27-rot0-5/se_resnext50_32x4d_26_loss0.10_score0.90_val_loss0.12_val_score0.88_midd_1024.pt\",#8e-5-27-rot0-5\n",
    "               \"/kaggle/input/sn-hoa-8e-5-27-rot0-5/se_resnext50_32x4d_30_loss0.10_score0.90_val_loss0.13_val_score0.88_midd_1024.pt\",\n",
    "               \"/home/clay/research/kaggle/sennet/data/model_real_67.pt\"]#  31 8e 05  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ecf69",
   "metadata": {
    "papermill": {
     "duration": 0.00714,
     "end_time": "2024-01-05T10:47:41.561495",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.554355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbeeef7",
   "metadata": {
    "papermill": {
     "duration": 0.023851,
     "end_time": "2024-01-05T10:47:41.592552",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.568701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, CFG, weight=None):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=CFG.backbone, \n",
    "            encoder_weights=weight,\n",
    "            in_channels=CFG.in_chans,\n",
    "            classes=CFG.target_size,\n",
    "            activation=None,\n",
    "        )\n",
    "        self.batch=CFG.batch\n",
    "\n",
    "    def forward_(self, image):\n",
    "        output = self.model(image)\n",
    "        return output[:,0]\n",
    "    \n",
    "    def forward(self,x:tc.Tensor):\n",
    "        #x.shape=(batch,c,h,w)\n",
    "        x=x.to(tc.float32)\n",
    "        x=norm_with_clip(x.reshape(-1,*x.shape[2:])).reshape(x.shape)\n",
    "        \n",
    "        if CFG.input_size!=CFG.image_size:\n",
    "            x=nn.functional.interpolate(x,size=(CFG.input_size,CFG.input_size),mode='bilinear',align_corners=True)\n",
    "        \n",
    "        shape=x.shape\n",
    "        x=[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(4)]\n",
    "        x=tc.cat(x,dim=0)\n",
    "        with autocast():\n",
    "            with tc.no_grad():\n",
    "                x=[self.forward_(x[i*self.batch:(i+1)*self.batch]) for i in range(x.shape[0]//self.batch+1)]\n",
    "                # batch=64,64...48\n",
    "                x=tc.cat(x,dim=0)\n",
    "        x=x.sigmoid()\n",
    "        x=x.reshape(4,shape[0],*shape[2:])\n",
    "        x=[tc.rot90(x[i],k=-i,dims=(-2,-1)) for i in range(4)]\n",
    "        x=tc.stack(x,dim=0).mean(0)\n",
    "        \n",
    "        if CFG.input_size!=CFG.image_size:\n",
    "            x=nn.functional.interpolate(x[None],size=(CFG.image_size,CFG.image_size),mode='bilinear',align_corners=True)[0]\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_model(weight=None):\n",
    "    load_dotenv()\n",
    "\n",
    "    print('model_name', CFG.model_name)\n",
    "    print('backbone', CFG.backbone)\n",
    "\n",
    "    model = CustomModel(CFG, weight)\n",
    "\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46b4f7",
   "metadata": {
    "papermill": {
     "duration": 0.006988,
     "end_time": "2024-01-05T10:47:41.607297",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.600309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8138d",
   "metadata": {
    "papermill": {
     "duration": 0.02279,
     "end_time": "2024-01-05T10:47:41.637549",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.614759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_1024(img , image_size = 1024):\n",
    "    if image_size > img.shape[1]:\n",
    "       img = np.rot90(img)\n",
    "       start1 = (CFG.image_size - img.shape[0])//2 \n",
    "       top =     img[0                    : start1,   0: img.shape[1] ]\n",
    "       bottom  = img[img.shape[0] -start1 : img.shape[0],   0 : img.shape[1] ]\n",
    "       img_result = np.concatenate((top,img,bottom ),axis=0)\n",
    "       img_result = np.rot90(img_result)\n",
    "       img_result = np.rot90(img_result)\n",
    "       img_result = np.rot90(img_result)\n",
    "    else :\n",
    "       img_result = img\n",
    "    return img_result\n",
    "\n",
    "def to_1024_no_rot(img, image_size = 1024):\n",
    "    if image_size > img.shape[0]:  \n",
    "       start1 = ( image_size - img.shape[0])//2\n",
    "       top =     img[0                    : start1,   0: img.shape[1] ]\n",
    "       bottom  = img[img.shape[0] -start1 : img.shape[0],   0 : img.shape[1] ]\n",
    "       img_result = np.concatenate((top,img,bottom ),axis=0)\n",
    "    else: \n",
    "       img_result = img\n",
    "    return img_result\n",
    "\n",
    "def to_1024_1024(img  , image_size = 1024 ):\n",
    "     img_result = to_1024(img, image_size )\n",
    "     return img_result\n",
    "    \n",
    "def to_original ( im_after, img, image_size = 1024 ):\n",
    "    top_ = 0\n",
    "    left_ = 0\n",
    "    if (im_after.shape[0] > img.shape[0]):\n",
    "             top_  = ( image_size - img.shape[0])//2 \n",
    "    if    (im_after.shape[1] > img.shape[1]) :\n",
    "             left_  = ( image_size - img.shape[1])//2  \n",
    "    if (top_>0)or (left_>0) :\n",
    "             img_result = im_after[top_  : img.shape[0] + top_,   left_: img.shape[1] + left_ ]\n",
    "    else:\n",
    "             img_result = im_after\n",
    "    return img_result  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc1567",
   "metadata": {
    "papermill": {
     "duration": 0.007406,
     "end_time": "2024-01-05T10:47:41.652822",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.645416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfd50e",
   "metadata": {
    "papermill": {
     "duration": 0.036158,
     "end_time": "2024-01-05T10:47:41.696374",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.660216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixel = mask.flatten()\n",
    "    pixel = np.concatenate([[0], pixel, [0]])\n",
    "    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n",
    "    run[1::2] -= run[::2]\n",
    "    rle = ' '.join(str(r) for r in run)\n",
    "    if rle == '':\n",
    "        rle = '1 0'\n",
    "    return rle\n",
    "\n",
    "def min_max_normalization(x:tc.Tensor)->tc.Tensor:\n",
    "    \"\"\"input.shape=(batch,f1,...)\"\"\"\n",
    "    shape=x.shape\n",
    "    if x.ndim>2:\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "    \n",
    "    min_=x.min(dim=-1,keepdim=True)[0]\n",
    "    max_=x.max(dim=-1,keepdim=True)[0]\n",
    "    if min_.mean()==0 and max_.mean()==1:\n",
    "        return x.reshape(shape)\n",
    "    \n",
    "    x=(x-min_)/(max_-min_+1e-9)\n",
    "    return x.reshape(shape)\n",
    "\n",
    "def norm_with_clip(x:tc.Tensor,smooth=1e-5):\n",
    "    dim=list(range(1,x.ndim))\n",
    "    mean=x.mean(dim=dim,keepdim=True)\n",
    "    std=x.std(dim=dim,keepdim=True)\n",
    "    x=(x-mean)/(std+smooth)\n",
    "    x[x>5]=(x[x>5]-5)*1e-3 +5\n",
    "    x[x<-3]=(x[x<-3]+3)*1e-3-3\n",
    "    return x\n",
    "\n",
    "class Data_loader(Dataset):\n",
    "    def __init__(self,path,s=\"/images/\"):\n",
    "        self.paths=glob(path+f\"{s}*.tif\")\n",
    "        self.paths.sort()\n",
    "        self.bool=s==\"/labels/\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img=cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n",
    "        img = to_1024_1024(img , image_size = CFG.image_size )\n",
    "        \n",
    "        img=tc.from_numpy(img.copy())\n",
    "        if self.bool:\n",
    "            img=img.to(tc.bool)\n",
    "        else:\n",
    "            img=img.to(tc.uint8)\n",
    "        return img\n",
    "\n",
    "def load_data(path,s):\n",
    "    data_loader=Data_loader(path,s)\n",
    "    data_loader=DataLoader(data_loader, batch_size=16, num_workers=2)\n",
    "    data=[]\n",
    "    for x in tqdm(data_loader):\n",
    "        data.append(x)\n",
    "    x=tc.cat(data,dim=0)\n",
    "    ########################################################################\n",
    "    TH=x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH:int = np.partition(TH, index)[index]\n",
    "    x[x>TH]=int(TH)\n",
    "    ########################################################################\n",
    "    TH=x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH:int = np.partition(TH, -index)[-index]\n",
    "    x[x<TH]=int(TH)\n",
    "    ########################################################################\n",
    "    #x=(min_max_normalization(x.to(tc.float16))*255).to(tc.uint8)\n",
    "    return x\n",
    "\n",
    "class Pipeline_Dataset(Dataset):\n",
    "    def __init__(self,x,path):\n",
    "        self.img_paths  = glob(path+\"/images/*\")\n",
    "        self.img_paths.sort()\n",
    "        self.in_chan = CFG.in_chans\n",
    "        z=tc.zeros(self.in_chan//2,*x.shape[1:],dtype=x.dtype)\n",
    "        self.x=tc.cat((z,x,z),dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]-self.in_chan+1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x  = self.x[index:index+self.in_chan]\n",
    "        return x,index\n",
    "    \n",
    "    def get_mark(self,index):\n",
    "        id=self.img_paths[index].split(\"/\")[-3:]\n",
    "        id.pop(1)\n",
    "        id=\"_\".join(id)\n",
    "        return id[:-4]\n",
    "    \n",
    "    def get_marks(self):\n",
    "        ids=[]\n",
    "        for index in range(len(self)):\n",
    "            ids.append(self.get_mark(index))\n",
    "        return ids\n",
    "\n",
    "def add_edge(x:tc.Tensor,edge:int):\n",
    "    #x=(C,H,W)\n",
    "    #output=(C,H+2*edge,W+2*edge)\n",
    "    mean_=int(x.to(tc.float32).mean())\n",
    "    x=tc.cat([x,tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_],dim=1)\n",
    "    x=tc.cat([x,tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_],dim=2)\n",
    "    x=tc.cat([tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_,x],dim=1)\n",
    "    x=tc.cat([tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_,x],dim=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c34bcd",
   "metadata": {
    "papermill": {
     "duration": 0.00755,
     "end_time": "2024-01-05T10:47:41.711527",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.703977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43925735",
   "metadata": {
    "papermill": {
     "duration": 2.70181,
     "end_time": "2024-01-05T10:47:44.421064",
     "exception": false,
     "start_time": "2024-01-05T10:47:41.719254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=build_model()\n",
    "load_status = model.load_state_dict(tc.load(CFG.model_path[ model_path_i ],\"cpu\"))\n",
    "model.eval()\n",
    "model=DataParallel(model)\n",
    "print(load_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28031ea",
   "metadata": {
    "papermill": {
     "duration": 0.030077,
     "end_time": "2024-01-05T10:47:44.459345",
     "exception": false,
     "start_time": "2024-01-05T10:47:44.429268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_output(debug=False):\n",
    "    outputs=[]\n",
    "    \n",
    "    if debug:\n",
    "        paths=[\"/kaggle/input/blood-vessel-segmentation/train/kidney_2\"]\n",
    "    else:\n",
    "        paths=glob(\"/kaggle/input/blood-vessel-segmentation/test/*\")\n",
    "    paths=[\"/home/clay/research/kaggle/sennet/data/blood-vessel-segmentation/train/kidney_3_dense\"]\n",
    "    outputs=[[],[]]\n",
    "    for path in paths:\n",
    "        x=load_data(path,\"/images/\")\n",
    "        # labels=tc.zeros_like(x,dtype=tc.uint8)\n",
    "        labels=tc.zeros_like(x,dtype=tc.float16)\n",
    "        mark=Pipeline_Dataset(x,path).get_marks()\n",
    "        \n",
    "        \n",
    "        for axis in [0]:\n",
    "        # for axis in [0,1,2]:\n",
    "            debug_count=0\n",
    "            if axis==0:\n",
    "                x_=x\n",
    "                labels_=labels\n",
    "            elif axis==1:\n",
    "                x_=x.permute(1,2,0)\n",
    "                labels_=labels.permute(1,2,0)\n",
    "            elif axis==2:\n",
    "                x_=x.permute(2,0,1)\n",
    "                labels_=labels.permute(2,0,1)\n",
    "            if x.shape[0]==3 and axis!=0:\n",
    "                break\n",
    "            dataset=Pipeline_Dataset(x_,path)\n",
    "            dataloader=DataLoader(dataset,batch_size=1,shuffle=False,num_workers=1)\n",
    "            shape=dataset.x.shape[-2:]\n",
    "            x1_list = np.arange(0, shape[0]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n",
    "            y1_list = np.arange(0, shape[1]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n",
    "            for img,index in tqdm(dataloader):\n",
    "                #img=(1,C,H,W)\n",
    "                img=img.to(\"cuda:0\")\n",
    "                img=add_edge(img[0],CFG.tile_size//2)[None]\n",
    "\n",
    "                mask_pred = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n",
    "                mask_count = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n",
    "\n",
    "                indexs=[]\n",
    "                chip=[]\n",
    "                bboxes=[]\n",
    "                for y1 in y1_list:\n",
    "                    for x1 in x1_list:\n",
    "                        x2 = x1 + CFG.tile_size\n",
    "                        y2 = y1 + CFG.tile_size\n",
    "                        indexs.append([x1+CFG.drop_egde_pixel,x2-CFG.drop_egde_pixel,\n",
    "                                       y1+CFG.drop_egde_pixel,y2-CFG.drop_egde_pixel])\n",
    "                        chip.append(img[...,x1:x2,y1:y2])\n",
    "                        bboxes.append([y1, x1, y2, x2])\n",
    "\n",
    "                model_batch = tc.cat(chip)\n",
    "\n",
    "                y_preds = model.forward(model_batch).to(device=0)\n",
    "\n",
    "                # # ====== debug stuffs =========\n",
    "                # print(f\"{model_batch.shape}\")\n",
    "                # print(f\"{CFG.stride=}\")\n",
    "                # print(f\"{len(bboxes)=}\")\n",
    "                # for _i, b in enumerate(bboxes):\n",
    "                #     print(f\"bbox[{_i}] = {b} : w={shape[1]}, h={shape[0]}\")\n",
    "                # print(f\"{y_preds.min()}, {y_preds.max()}\")\n",
    "                # # =============================\n",
    "                \n",
    "                if CFG.drop_egde_pixel:\n",
    "                    y_preds=y_preds[...,CFG.drop_egde_pixel:-CFG.drop_egde_pixel,\n",
    "                                        CFG.drop_egde_pixel:-CFG.drop_egde_pixel]\n",
    "                for i,(x1,x2,y1,y2) in enumerate(indexs):\n",
    "                    mask_pred[...,x1:x2, y1:y2] += y_preds[i]\n",
    "                    mask_count[...,x1:x2, y1:y2] += 1\n",
    "\n",
    "                # mask_pred /= mask_count\n",
    "                mask_pred /= (mask_count + 1e-8)\n",
    "\n",
    "                #Rrecover\n",
    "                mask_pred=mask_pred[...,CFG.tile_size//2:-CFG.tile_size//2,CFG.tile_size//2:-CFG.tile_size//2]\n",
    "                \n",
    "                # labels_[index]+=(mask_pred[0]*255 /3 ).to(tc.uint8).cpu()\n",
    "                labels_[index] += mask_pred[0].cpu()\n",
    "                if debug:\n",
    "                    debug_count+=1\n",
    "                    plt.subplot(121)\n",
    "                    plt.imshow(img[0,CFG.in_chans//2].cpu().detach().numpy())\n",
    "                    plt.subplot(122)\n",
    "                    plt.imshow(mask_pred[0].cpu().detach().numpy())\n",
    "                    plt.show()\n",
    "                    if debug_count>3:\n",
    "                        break\n",
    "        outputs[0].append(labels)\n",
    "        outputs[1].extend(mark)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35e075",
   "metadata": {
    "papermill": {
     "duration": 229.782334,
     "end_time": "2024-01-05T10:51:34.249436",
     "exception": false,
     "start_time": "2024-01-05T10:47:44.467102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# is_submit=len(glob(\"/kaggle/input/blood-vessel-segmentation/test/kidney_5/images/*.tif\"))!=3\n",
    "is_submit=True\n",
    "output, ids = get_output(not is_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12791abf-8ec1-4516-a521-355472a4e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b91fdd-2eeb-4002-81d1-8683ca58cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "TH=[x.flatten().numpy() for x in output]\n",
    "TH=np.concatenate(TH)\n",
    "index = -int(len(TH) * CFG.th_percentile)\n",
    "TH:int = np.partition(TH, index)[index]\n",
    "print([(x.max(), x.min()) for x in output])\n",
    "print(f\"{TH=}\")\n",
    "print(f\"{1-TH=}\")\n",
    "\n",
    "img=cv2.imread(\"/home/clay/research/kaggle/sennet/data/blood-vessel-segmentation/train/kidney_3_dense/images/0496.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "####################################\n",
    "submission_df=[]\n",
    "debug_count=0\n",
    "for index in range(len(ids)):\n",
    "    id=ids[index]\n",
    "    i=0\n",
    "    for x in output:\n",
    "        if index>=len(x):\n",
    "            index-=len(x)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    mask_pred=(output[i][index]>TH).numpy()\n",
    "    \n",
    "    mask_pred2 = to_original ( mask_pred, img, image_size = 1024 )\n",
    "    mask_pred =  mask_pred2.copy()\n",
    "    \n",
    "    ####################################\n",
    "    if not is_submit:\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(mask_pred)\n",
    "        plt.show()\n",
    "        debug_count+=1\n",
    "        if debug_count>6:\n",
    "            break\n",
    "        \n",
    "    rle = rle_encode(mask_pred)\n",
    "    \n",
    "    submission_df.append(\n",
    "        pd.DataFrame(data={\n",
    "            'id'  : id,\n",
    "            'rle' : rle,\n",
    "        },index=[0])\n",
    "    )\n",
    "\n",
    "submission_df =pd.concat(submission_df)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385eadff-defb-4cf5-b9bc-43f655c4be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from sennet.custom_modules.metrics.surface_dice_metric_fast import compute_surface_dice_score\n",
    "from sennet.environments.constants import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce7b47-08cf-440b-97a9-91edd8815ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(DATA_DIR / \"train_rles.csv\")\n",
    "df = submission_df.reset_index(drop=True).copy()\n",
    "\n",
    "# note: valid for k3d only\n",
    "width = 1706\n",
    "height = 1510\n",
    "df[\"width\"] = width\n",
    "df[\"height\"] = height\n",
    "filtered_label = label.loc[label[\"id\"].isin(df[\"id\"])].copy().sort_values(\"id\").reset_index()\n",
    "filtered_label[\"width\"] = width\n",
    "filtered_label[\"height\"] = height\n",
    "score = compute_surface_dice_score(\n",
    "    submit=df,\n",
    "    label=filtered_label,\n",
    ")\n",
    "print(f\"{score=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d6c0a-edc1-4bf9-be44-5dfc7b4209d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de3ada-fa3d-4bba-b81e-031589e78c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9d0a2-22d9-47f6-8d21-6d2b26328de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f6591-3297-4846-b7a8-eee476dca212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78197d70-2ea8-48cb-b2bf-581442e8105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"len\"] = df[\"rle\"].str.len()\n",
    "df.sort_values(\"len\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7192b7b-7de0-4e2c-802b-b559cefb5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 4087873,
     "sourceId": 7187369,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4229452,
     "isSourceIdPinned": true,
     "sourceId": 7312958,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4243245,
     "isSourceIdPinned": true,
     "sourceId": 7317236,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4249424,
     "isSourceIdPinned": true,
     "sourceId": 7322239,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4250312,
     "isSourceIdPinned": true,
     "sourceId": 7336367,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 156694315,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 264.620702,
   "end_time": "2024-01-05T10:51:36.403835",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-05T10:47:11.783133",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
