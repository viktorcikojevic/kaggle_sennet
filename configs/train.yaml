defaults:
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe
  - _self_

val_check_interval: 1000
batch_size: 32
accumulate_grad_batches: 32
num_workers: 16
dry_logger: false
exp_name: three_d_seg
group_name: null # maybe this would be useful for grouping experiments when we do hyperparameter search
patience: 5
max_epochs: 10


model:
  type: WrappedUNet3D
  kwargs:
    in_channels: 1
    out_channels: 1
    pretrained: "unet3d.pytorch"
    num_groups: 8
    f_maps: 32
    final_sigmoid: false
    is_segmentation: false
    is3d: true


optimiser:
  type: "AdamW"
  log_lr: -4 # sets lr = 10^{-log_lr}. If ls is not null, then it is used instead of log_lr
  kwargs:
    lr: null



loss:
  - type: BCELoss
    weight: 1.0
  - type: DiceLoss
    weight: 1.0
    kwargs:
      smooth: 0.0001
  - type: FocalLoss
    weight: 1.0
    kwargs:
      gamma: 2.0


train_folders:
  - kidney_1_dense

val_folders:
#  - kidney_1_dense
#   - kidney_3_dense
   - kidney_3_sparse


dataset:
  train_substride: 0.25
  val_substride: 1.0
  kwargs:
    crop_size: 512
    n_take_channels: 10
    reduce_zero_label: False
    assert_label_exists: True
    channel_start: 0
    channel_end: null
    sample_with_mask: false

    crop_size_range: null
    output_crop_size: null
    to_float32: true
    channels_jitter: 0
    p_channel_jitter: 0.0
    load_ann: true
    seg_fill_val: 0
    crop_location_noise: 100



hydra:
  sweeper:
    sampler:
      seed: 42
    direction: maximize
    storage: null
    n_trials: 20
    n_jobs: 1
    params:
      optimiser.log_lr: range(-4, -3, 1)
